# activation functions: sigmoid, tanh, ReLU
뉴럴 네트워크의 non-linearity 표현을 가능하게 해주는 activation function에 관한 포스트입니다.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTc3Nzk4MjMxMF19
-->